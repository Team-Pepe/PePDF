{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 10, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/jaena/Downloads/toolsapp/lib/services/pdf-service.ts"],"sourcesContent":["import { PDFDocument, rgb, StandardFonts } from \"pdf-lib\"\r\nimport { Document, Packer, Paragraph, TextRun } from \"docx\"\r\n\r\n// Dynamic import for PDF.js to avoid SSR issues\r\nlet pdfjsLib: any = null\r\n\r\n// Configure PDF.js worker only on client side\r\nif (typeof window !== \"undefined\") {\r\n  import(\"pdfjs-dist\").then((pdfjs) => {\r\n    pdfjsLib = pdfjs\r\n    pdfjsLib.GlobalWorkerOptions.workerSrc = \"/pdf.worker.min.js\"\r\n  })\r\n}\r\n\r\nexport interface PDFToWordOptions {\r\n  file: File\r\n  preserveFormatting?: boolean\r\n  includeImages?: boolean\r\n  includeTables?: boolean\r\n}\r\n\r\nexport interface PDFToImagesOptions {\r\n  file: File\r\n  format: \"png\" | \"jpeg\" | \"webp\"\r\n  quality?: number\r\n  scale?: number\r\n}\r\n\r\nexport interface CompressPDFOptions {\r\n  file: File\r\n  quality?: 'low' | 'medium' | 'high'\r\n}\r\n\r\n// Encryption removed from project\r\n\r\nexport interface MergePDFOptions {\r\n  files: File[]\r\n}\r\n\r\nexport class PDFService {\r\n  /**\r\n   * Extract text from PDF file\r\n   */\r\n  static async extractTextFromPDF(file: File): Promise<string[]> {\r\n    if (typeof window === \"undefined\") {\r\n      throw new Error(\"PDF text extraction is only available on the client side\")\r\n    }\r\n\r\n    if (!pdfjsLib) {\r\n      pdfjsLib = await import(\"pdfjs-dist\")\r\n      pdfjsLib.GlobalWorkerOptions.workerSrc = \"/pdf.worker.min.js\"\r\n    }\r\n\r\n    try {\r\n      const arrayBuffer = await file.arrayBuffer()\r\n      const pdf = await pdfjsLib.getDocument({ data: arrayBuffer }).promise\r\n      const textPages: string[] = []\r\n\r\n      for (let i = 1; i <= pdf.numPages; i++) {\r\n        const page = await pdf.getPage(i)\r\n        const textContent = await page.getTextContent()\r\n        \r\n        let pageText = \"\"\r\n        textContent.items.forEach((item: any) => {\r\n          if (item.str) {\r\n            pageText += item.str + \" \"\r\n          }\r\n        })\r\n        \r\n        textPages.push(pageText.trim())\r\n      }\r\n\r\n      return textPages\r\n    } catch (error) {\r\n      console.error('Error extracting text from PDF:', error)\r\n      throw new Error('Failed to extract text from PDF')\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Convert PDF to Word document\r\n   */\r\n  static async convertToWord(options: PDFToWordOptions): Promise<Blob> {\r\n    const { file, preserveFormatting = true, includeImages = false, includeTables = false } = options\r\n    \r\n    try {\r\n      // Extract text from PDF\r\n      const textPages = await this.extractTextFromPDF(file)\r\n      \r\n      // Create Word document\r\n      const doc = new Document({\r\n        sections: [{\r\n          properties: {},\r\n          children: [\r\n            new Paragraph({\r\n              children: [\r\n                new TextRun({\r\n                  text: `Converted from: ${file.name}`,\r\n                  bold: true,\r\n                  size: 24,\r\n                }),\r\n              ],\r\n            }),\r\n            new Paragraph({ text: \"\" }), // Empty line\r\n            ...textPages.flatMap((pageText, index) => [\r\n              new Paragraph({\r\n                children: [\r\n                  new TextRun({\r\n                    text: `Page ${index + 1}`,\r\n                    bold: true,\r\n                    size: 20,\r\n                  }),\r\n                ],\r\n              }),\r\n              new Paragraph({ text: \"\" }), // Empty line\r\n              ...this.groupSentencesIntoParagraphs(pageText.split(/[.!?]+/))\r\n                .map(paragraph => new Paragraph({\r\n                  children: [\r\n                    new TextRun({\r\n                      text: paragraph.trim(),\r\n                      size: 20,\r\n                    }),\r\n                  ],\r\n                })),\r\n              new Paragraph({ text: \"\" }), // Empty line between pages\r\n            ])\r\n          ],\r\n        }],\r\n      })\r\n\r\n      // Generate Word document\r\n      const buffer = await Packer.toBuffer(doc)\r\n      return new Blob([new Uint8Array(buffer)], { \r\n        type: \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\" \r\n      })\r\n    } catch (error) {\r\n      console.error('Error converting PDF to Word:', error)\r\n      throw new Error('Failed to convert PDF to Word')\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Convert PDF to images\r\n   */\r\n  static async convertToImages(options: PDFToImagesOptions): Promise<Blob[]> {\r\n    if (typeof window === \"undefined\") {\r\n      throw new Error(\"PDF to images conversion is only available on the client side\")\r\n    }\r\n\r\n    if (!pdfjsLib) {\r\n      pdfjsLib = await import(\"pdfjs-dist\")\r\n      pdfjsLib.GlobalWorkerOptions.workerSrc = \"/pdf.worker.min.js\"\r\n    }\r\n\r\n    const { file, format, quality = 0.92, scale = 2.0 } = options\r\n    \r\n    try {\r\n      const arrayBuffer = await file.arrayBuffer()\r\n      const pdf = await pdfjsLib.getDocument({ data: arrayBuffer }).promise\r\n      const images: Blob[] = []\r\n\r\n      for (let i = 1; i <= pdf.numPages; i++) {\r\n        const page = await pdf.getPage(i)\r\n        const viewport = page.getViewport({ scale })\r\n        \r\n        const canvas = document.createElement('canvas')\r\n        const context = canvas.getContext('2d')!\r\n        canvas.height = viewport.height\r\n        canvas.width = viewport.width\r\n\r\n        await page.render({\r\n          canvasContext: context,\r\n          viewport: viewport\r\n        }).promise\r\n\r\n        const blob = await new Promise<Blob>((resolve) => {\r\n          canvas.toBlob((blob) => {\r\n            resolve(blob!)\r\n          }, `image/${format}`, quality)\r\n        })\r\n\r\n        images.push(blob)\r\n      }\r\n\r\n      return images\r\n    } catch (error) {\r\n      console.error('Error converting PDF to images:', error)\r\n      throw new Error('Failed to convert PDF to images')\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Compress PDF file\r\n   */\r\n  static async compress(options: CompressPDFOptions): Promise<Blob> {\r\n    const { file, quality = 'medium' } = options\r\n    \r\n    try {\r\n      const arrayBuffer = await file.arrayBuffer()\r\n      const pdfDoc = await PDFDocument.load(arrayBuffer)\r\n\r\n      // Compression settings based on quality\r\n      const compressionOptions = {\r\n        low: { useObjectStreams: false, addDefaultPage: false },\r\n        medium: { useObjectStreams: true, addDefaultPage: false },\r\n        high: { useObjectStreams: true, addDefaultPage: false, compress: true }\r\n      }\r\n\r\n      const pdfBytes = await pdfDoc.save(compressionOptions[quality])\r\n      return new Blob([new Uint8Array(pdfBytes)], { type: \"application/pdf\" })\r\n    } catch (error) {\r\n      console.error('Error compressing PDF:', error)\r\n      throw new Error('Failed to compress PDF')\r\n    }\r\n  }\r\n\r\n  // encrypt method removed\r\n\r\n  /**\r\n   * Merge multiple PDF files\r\n   */\r\n  static async merge(options: MergePDFOptions): Promise<Blob> {\r\n    const { files } = options\r\n    \r\n    try {\r\n      const mergedPdf = await PDFDocument.create()\r\n\r\n      for (const file of files) {\r\n        const arrayBuffer = await file.arrayBuffer()\r\n        const pdf = await PDFDocument.load(arrayBuffer)\r\n        const copiedPages = await mergedPdf.copyPages(pdf, pdf.getPageIndices())\r\n        copiedPages.forEach((page) => mergedPdf.addPage(page))\r\n      }\r\n\r\n      const pdfBytes = await mergedPdf.save()\r\n      return new Blob([new Uint8Array(pdfBytes)], { type: \"application/pdf\" })\r\n    } catch (error) {\r\n      console.error('Error merging PDFs:', error)\r\n      throw new Error('Failed to merge PDFs')\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Group sentences into paragraphs for better Word formatting\r\n   */\r\n  private static groupSentencesIntoParagraphs(sentences: string[]): string[] {\r\n    const paragraphs: string[] = []\r\n    let currentParagraph = \"\"\r\n    \r\n    sentences.forEach((sentence) => {\r\n      const trimmedSentence = sentence.trim()\r\n      if (trimmedSentence) {\r\n        if (currentParagraph.length + trimmedSentence.length > 500) {\r\n          if (currentParagraph) {\r\n            paragraphs.push(currentParagraph.trim())\r\n          }\r\n          currentParagraph = trimmedSentence + \". \"\r\n        } else {\r\n          currentParagraph += trimmedSentence + \". \"\r\n        }\r\n      }\r\n    })\r\n    \r\n    if (currentParagraph.trim()) {\r\n      paragraphs.push(currentParagraph.trim())\r\n    }\r\n    \r\n    return paragraphs\r\n  }\r\n\r\n  /**\r\n   * Validate if file is a valid PDF\r\n   */\r\n  static async validatePDF(file: File): Promise<boolean> {\r\n    try {\r\n      const arrayBuffer = await file.arrayBuffer()\r\n      await PDFDocument.load(arrayBuffer)\r\n      return true\r\n    } catch {\r\n      return false\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Get PDF metadata\r\n   */\r\n  static async getPDFInfo(file: File): Promise<{\r\n    pageCount: number\r\n    title?: string\r\n    author?: string\r\n    subject?: string\r\n    creator?: string\r\n  }> {\r\n    if (typeof window === \"undefined\") {\r\n      throw new Error(\"PDF info extraction is only available on the client side\")\r\n    }\r\n\r\n    if (!pdfjsLib) {\r\n      pdfjsLib = await import(\"pdfjs-dist\")\r\n      pdfjsLib.GlobalWorkerOptions.workerSrc = \"/pdf.worker.min.js\"\r\n    }\r\n\r\n    try {\r\n      const arrayBuffer = await file.arrayBuffer()\r\n      const pdf = await pdfjsLib.getDocument({ data: arrayBuffer }).promise\r\n      const metadata = await pdf.getMetadata()\r\n      \r\n      return {\r\n        pageCount: pdf.numPages,\r\n        title: metadata.info?.Title,\r\n        author: metadata.info?.Author,\r\n        subject: metadata.info?.Subject,\r\n        creator: metadata.info?.Creator,\r\n      }\r\n    } catch (error) {\r\n      console.error('Error getting PDF info:', error)\r\n      throw new Error('Failed to get PDF information')\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Wrap text for better formatting\r\n   */\r\n  private static wrapText(text: string, maxLength: number): string[] {\r\n    const words = text.split(\" \")\r\n    const lines: string[] = []\r\n    let currentLine = \"\"\r\n\r\n    words.forEach((word) => {\r\n      if (currentLine.length + word.length + 1 <= maxLength) {\r\n        currentLine += (currentLine ? \" \" : \"\") + word\r\n      } else {\r\n        if (currentLine) lines.push(currentLine)\r\n        currentLine = word\r\n      }\r\n    })\r\n\r\n    if (currentLine) lines.push(currentLine)\r\n    return lines\r\n  }\r\n}\r\n"],"names":[],"mappings":";;;;AAAA;AAAA;AACA;;;AAEA,gDAAgD;AAChD,IAAI,WAAgB;AAEpB,8CAA8C;AAC9C;;AAgCO,MAAM;IACX;;GAEC,GACD,aAAa,mBAAmB,IAAU,EAAqB;QAC7D,wCAAmC;YACjC,MAAM,IAAI,MAAM;QAClB;QAEA,IAAI,CAAC,UAAU;YACb,WAAW;YACX,SAAS,mBAAmB,CAAC,SAAS,GAAG;QAC3C;QAEA,IAAI;YACF,MAAM,cAAc,MAAM,KAAK,WAAW;YAC1C,MAAM,MAAM,MAAM,SAAS,WAAW,CAAC;gBAAE,MAAM;YAAY,GAAG,OAAO;YACrE,MAAM,YAAsB,EAAE;YAE9B,IAAK,IAAI,IAAI,GAAG,KAAK,IAAI,QAAQ,EAAE,IAAK;gBACtC,MAAM,OAAO,MAAM,IAAI,OAAO,CAAC;gBAC/B,MAAM,cAAc,MAAM,KAAK,cAAc;gBAE7C,IAAI,WAAW;gBACf,YAAY,KAAK,CAAC,OAAO,CAAC,CAAC;oBACzB,IAAI,KAAK,GAAG,EAAE;wBACZ,YAAY,KAAK,GAAG,GAAG;oBACzB;gBACF;gBAEA,UAAU,IAAI,CAAC,SAAS,IAAI;YAC9B;YAEA,OAAO;QACT,EAAE,OAAO,OAAO;YACd,QAAQ,KAAK,CAAC,mCAAmC;YACjD,MAAM,IAAI,MAAM;QAClB;IACF;IAEA;;GAEC,GACD,aAAa,cAAc,OAAyB,EAAiB;QACnE,MAAM,EAAE,IAAI,EAAE,qBAAqB,IAAI,EAAE,gBAAgB,KAAK,EAAE,gBAAgB,KAAK,EAAE,GAAG;QAE1F,IAAI;YACF,wBAAwB;YACxB,MAAM,YAAY,MAAM,IAAI,CAAC,kBAAkB,CAAC;YAEhD,uBAAuB;YACvB,MAAM,MAAM,IAAI,kJAAQ,CAAC;gBACvB,UAAU;oBAAC;wBACT,YAAY,CAAC;wBACb,UAAU;4BACR,IAAI,mJAAS,CAAC;gCACZ,UAAU;oCACR,IAAI,iJAAO,CAAC;wCACV,MAAM,CAAC,gBAAgB,EAAE,KAAK,IAAI,EAAE;wCACpC,MAAM;wCACN,MAAM;oCACR;iCACD;4BACH;4BACA,IAAI,mJAAS,CAAC;gCAAE,MAAM;4BAAG;+BACtB,UAAU,OAAO,CAAC,CAAC,UAAU,QAAU;oCACxC,IAAI,mJAAS,CAAC;wCACZ,UAAU;4CACR,IAAI,iJAAO,CAAC;gDACV,MAAM,CAAC,KAAK,EAAE,QAAQ,GAAG;gDACzB,MAAM;gDACN,MAAM;4CACR;yCACD;oCACH;oCACA,IAAI,mJAAS,CAAC;wCAAE,MAAM;oCAAG;uCACtB,IAAI,CAAC,4BAA4B,CAAC,SAAS,KAAK,CAAC,WACjD,GAAG,CAAC,CAAA,YAAa,IAAI,mJAAS,CAAC;4CAC9B,UAAU;gDACR,IAAI,iJAAO,CAAC;oDACV,MAAM,UAAU,IAAI;oDACpB,MAAM;gDACR;6CACD;wCACH;oCACF,IAAI,mJAAS,CAAC;wCAAE,MAAM;oCAAG;iCAC1B;yBACF;oBACH;iBAAE;YACJ;YAEA,yBAAyB;YACzB,MAAM,SAAS,MAAM,gJAAM,CAAC,QAAQ,CAAC;YACrC,OAAO,IAAI,KAAK;gBAAC,IAAI,WAAW;aAAQ,EAAE;gBACxC,MAAM;YACR;QACF,EAAE,OAAO,OAAO;YACd,QAAQ,KAAK,CAAC,iCAAiC;YAC/C,MAAM,IAAI,MAAM;QAClB;IACF;IAEA;;GAEC,GACD,aAAa,gBAAgB,OAA2B,EAAmB;QACzE,wCAAmC;YACjC,MAAM,IAAI,MAAM;QAClB;QAEA,IAAI,CAAC,UAAU;YACb,WAAW;YACX,SAAS,mBAAmB,CAAC,SAAS,GAAG;QAC3C;QAEA,MAAM,EAAE,IAAI,EAAE,MAAM,EAAE,UAAU,IAAI,EAAE,QAAQ,GAAG,EAAE,GAAG;QAEtD,IAAI;YACF,MAAM,cAAc,MAAM,KAAK,WAAW;YAC1C,MAAM,MAAM,MAAM,SAAS,WAAW,CAAC;gBAAE,MAAM;YAAY,GAAG,OAAO;YACrE,MAAM,SAAiB,EAAE;YAEzB,IAAK,IAAI,IAAI,GAAG,KAAK,IAAI,QAAQ,EAAE,IAAK;gBACtC,MAAM,OAAO,MAAM,IAAI,OAAO,CAAC;gBAC/B,MAAM,WAAW,KAAK,WAAW,CAAC;oBAAE;gBAAM;gBAE1C,MAAM,SAAS,SAAS,aAAa,CAAC;gBACtC,MAAM,UAAU,OAAO,UAAU,CAAC;gBAClC,OAAO,MAAM,GAAG,SAAS,MAAM;gBAC/B,OAAO,KAAK,GAAG,SAAS,KAAK;gBAE7B,MAAM,KAAK,MAAM,CAAC;oBAChB,eAAe;oBACf,UAAU;gBACZ,GAAG,OAAO;gBAEV,MAAM,OAAO,MAAM,IAAI,QAAc,CAAC;oBACpC,OAAO,MAAM,CAAC,CAAC;wBACb,QAAQ;oBACV,GAAG,CAAC,MAAM,EAAE,QAAQ,EAAE;gBACxB;gBAEA,OAAO,IAAI,CAAC;YACd;YAEA,OAAO;QACT,EAAE,OAAO,OAAO;YACd,QAAQ,KAAK,CAAC,mCAAmC;YACjD,MAAM,IAAI,MAAM;QAClB;IACF;IAEA;;GAEC,GACD,aAAa,SAAS,OAA2B,EAAiB;QAChE,MAAM,EAAE,IAAI,EAAE,UAAU,QAAQ,EAAE,GAAG;QAErC,IAAI;YACF,MAAM,cAAc,MAAM,KAAK,WAAW;YAC1C,MAAM,SAAS,MAAM,+JAAW,CAAC,IAAI,CAAC;YAEtC,wCAAwC;YACxC,MAAM,qBAAqB;gBACzB,KAAK;oBAAE,kBAAkB;oBAAO,gBAAgB;gBAAM;gBACtD,QAAQ;oBAAE,kBAAkB;oBAAM,gBAAgB;gBAAM;gBACxD,MAAM;oBAAE,kBAAkB;oBAAM,gBAAgB;oBAAO,UAAU;gBAAK;YACxE;YAEA,MAAM,WAAW,MAAM,OAAO,IAAI,CAAC,kBAAkB,CAAC,QAAQ;YAC9D,OAAO,IAAI,KAAK;gBAAC,IAAI,WAAW;aAAU,EAAE;gBAAE,MAAM;YAAkB;QACxE,EAAE,OAAO,OAAO;YACd,QAAQ,KAAK,CAAC,0BAA0B;YACxC,MAAM,IAAI,MAAM;QAClB;IACF;IAEA,yBAAyB;IAEzB;;GAEC,GACD,aAAa,MAAM,OAAwB,EAAiB;QAC1D,MAAM,EAAE,KAAK,EAAE,GAAG;QAElB,IAAI;YACF,MAAM,YAAY,MAAM,+JAAW,CAAC,MAAM;YAE1C,KAAK,MAAM,QAAQ,MAAO;gBACxB,MAAM,cAAc,MAAM,KAAK,WAAW;gBAC1C,MAAM,MAAM,MAAM,+JAAW,CAAC,IAAI,CAAC;gBACnC,MAAM,cAAc,MAAM,UAAU,SAAS,CAAC,KAAK,IAAI,cAAc;gBACrE,YAAY,OAAO,CAAC,CAAC,OAAS,UAAU,OAAO,CAAC;YAClD;YAEA,MAAM,WAAW,MAAM,UAAU,IAAI;YACrC,OAAO,IAAI,KAAK;gBAAC,IAAI,WAAW;aAAU,EAAE;gBAAE,MAAM;YAAkB;QACxE,EAAE,OAAO,OAAO;YACd,QAAQ,KAAK,CAAC,uBAAuB;YACrC,MAAM,IAAI,MAAM;QAClB;IACF;IAEA;;GAEC,GACD,OAAe,6BAA6B,SAAmB,EAAY;QACzE,MAAM,aAAuB,EAAE;QAC/B,IAAI,mBAAmB;QAEvB,UAAU,OAAO,CAAC,CAAC;YACjB,MAAM,kBAAkB,SAAS,IAAI;YACrC,IAAI,iBAAiB;gBACnB,IAAI,iBAAiB,MAAM,GAAG,gBAAgB,MAAM,GAAG,KAAK;oBAC1D,IAAI,kBAAkB;wBACpB,WAAW,IAAI,CAAC,iBAAiB,IAAI;oBACvC;oBACA,mBAAmB,kBAAkB;gBACvC,OAAO;oBACL,oBAAoB,kBAAkB;gBACxC;YACF;QACF;QAEA,IAAI,iBAAiB,IAAI,IAAI;YAC3B,WAAW,IAAI,CAAC,iBAAiB,IAAI;QACvC;QAEA,OAAO;IACT;IAEA;;GAEC,GACD,aAAa,YAAY,IAAU,EAAoB;QACrD,IAAI;YACF,MAAM,cAAc,MAAM,KAAK,WAAW;YAC1C,MAAM,+JAAW,CAAC,IAAI,CAAC;YACvB,OAAO;QACT,EAAE,OAAM;YACN,OAAO;QACT;IACF;IAEA;;GAEC,GACD,aAAa,WAAW,IAAU,EAM/B;QACD,wCAAmC;YACjC,MAAM,IAAI,MAAM;QAClB;QAEA,IAAI,CAAC,UAAU;YACb,WAAW;YACX,SAAS,mBAAmB,CAAC,SAAS,GAAG;QAC3C;QAEA,IAAI;YACF,MAAM,cAAc,MAAM,KAAK,WAAW;YAC1C,MAAM,MAAM,MAAM,SAAS,WAAW,CAAC;gBAAE,MAAM;YAAY,GAAG,OAAO;YACrE,MAAM,WAAW,MAAM,IAAI,WAAW;YAEtC,OAAO;gBACL,WAAW,IAAI,QAAQ;gBACvB,OAAO,SAAS,IAAI,EAAE;gBACtB,QAAQ,SAAS,IAAI,EAAE;gBACvB,SAAS,SAAS,IAAI,EAAE;gBACxB,SAAS,SAAS,IAAI,EAAE;YAC1B;QACF,EAAE,OAAO,OAAO;YACd,QAAQ,KAAK,CAAC,2BAA2B;YACzC,MAAM,IAAI,MAAM;QAClB;IACF;IAEA;;GAEC,GACD,OAAe,SAAS,IAAY,EAAE,SAAiB,EAAY;QACjE,MAAM,QAAQ,KAAK,KAAK,CAAC;QACzB,MAAM,QAAkB,EAAE;QAC1B,IAAI,cAAc;QAElB,MAAM,OAAO,CAAC,CAAC;YACb,IAAI,YAAY,MAAM,GAAG,KAAK,MAAM,GAAG,KAAK,WAAW;gBACrD,eAAe,CAAC,cAAc,MAAM,EAAE,IAAI;YAC5C,OAAO;gBACL,IAAI,aAAa,MAAM,IAAI,CAAC;gBAC5B,cAAc;YAChB;QACF;QAEA,IAAI,aAAa,MAAM,IAAI,CAAC;QAC5B,OAAO;IACT;AACF","debugId":null}},
    {"offset": {"line": 309, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/jaena/Downloads/toolsapp/lib/services/translation-service.ts"],"sourcesContent":["// TranslationService: Offline PDF translation using local MarianMT models via transformers.js\n// Works entirely in the browser. No API keys or third-party services.\n\nimport { PDFService } from '@/lib/services/pdf-service'\n\nexport type LanguageCode = 'en' | 'es' | 'fr' | 'de' | 'it' | 'pt'\n\nexport interface TranslatePDFOptions {\n  file: File\n  sourceLang: LanguageCode\n  targetLang: LanguageCode\n}\n\n// Map language pairs to local model IDs (MarianMT converted models for transformers.js)\nconst MODEL_MAP: Record<LanguageCode, Partial<Record<LanguageCode, string>>> = {\n  en: { es: 'Xenova/opus-mt-en-es', fr: 'Xenova/opus-mt-en-fr', de: 'Xenova/opus-mt-en-de', it: 'Xenova/opus-mt-en-it', pt: 'Xenova/opus-mt-en-pt' },\n  es: { en: 'Xenova/opus-mt-es-en', fr: 'Xenova/opus-mt-es-fr', de: 'Xenova/opus-mt-es-de', it: 'Xenova/opus-mt-es-it', pt: 'Xenova/opus-mt-es-pt' },\n  fr: { en: 'Xenova/opus-mt-fr-en', es: 'Xenova/opus-mt-fr-es', de: 'Xenova/opus-mt-fr-de', it: 'Xenova/opus-mt-fr-it', pt: 'Xenova/opus-mt-fr-pt' },\n  de: { en: 'Xenova/opus-mt-de-en', es: 'Xenova/opus-mt-de-es', fr: 'Xenova/opus-mt-de-fr', it: 'Xenova/opus-mt-de-it', pt: 'Xenova/opus-mt-de-pt' },\n  it: { en: 'Xenova/opus-mt-it-en', es: 'Xenova/opus-mt-it-es', fr: 'Xenova/opus-mt-it-fr', de: 'Xenova/opus-mt-it-de', pt: 'Xenova/opus-mt-it-pt' },\n  pt: { en: 'Xenova/opus-mt-pt-en', es: 'Xenova/opus-mt-pt-es', fr: 'Xenova/opus-mt-pt-fr', de: 'Xenova/opus-mt-pt-de', it: 'Xenova/opus-mt-pt-it' },\n}\n\ntype TranslatorPipeline = (text: string) => Promise<{ translation_text: string } | Array<{ translation_text: string }>>\n\nexport class TranslationService {\n  private static cache: Record<string, Promise<TranslatorPipeline>> = {}\n\n  /**\n   * Translate a full PDF file and return a new PDF blob with translated text.\n   */\n  static async translatePDF(options: TranslatePDFOptions): Promise<Blob> {\n    const { file, sourceLang, targetLang } = options\n\n    if (typeof window === 'undefined') {\n      throw new Error('PDF translation is only available on the client side')\n    }\n\n    const modelId = this.getModelId(sourceLang, targetLang)\n    const translator = await this.getTranslator(modelId)\n\n    // Extract text per page\n    const pages = await PDFService.extractTextFromPDF(file)\n\n    // Translate each page with chunking to avoid context limits\n    const translatedPages = [] as string[]\n    for (const pageText of pages) {\n      const translated = await this.translateLargeText(pageText, await translator)\n      translatedPages.push(translated)\n    }\n\n    // Create a new PDF with translated text\n    const translatedPdf = await PDFService.createPDFfromTextPages(translatedPages)\n    return translatedPdf\n  }\n\n  /** Get the model ID for a language pair. */\n  private static getModelId(src: LanguageCode, tgt: LanguageCode): string {\n    if (src === tgt) throw new Error('El idioma de origen y destino no pueden ser iguales')\n    const id = MODEL_MAP[src]?.[tgt]\n    if (!id) throw new Error(`No hay modelo local configurado para ${src}→${tgt}`)\n    return id\n  }\n\n  /** Lazily initialize and cache the translation pipeline using local models only. */\n  private static async getTranslator(modelId: string): Promise<TranslatorPipeline> {\n    if (!this.cache[modelId]) {\n      this.cache[modelId] = (async () => {\n        // Dynamic import to avoid SSR issues\n        // Ensure transformers.js detects browser correctly under Next/Turbopack.\n        // Provide a safe `process` shape so env detection in transformers.js doesn't call\n        // `Object.keys(undefined)` on `process.versions`.\n        {\n          const g = globalThis as any\n          // Create a safe process polyfill for browser bundles\n          if (!g.process || typeof g.process !== 'object') {\n            g.process = { versions: {}, env: {}, browser: true }\n          } else {\n            const p = g.process as any\n            if (p.versions == null) p.versions = {}\n            if (p.env == null) p.env = {}\n            p.browser = true\n          }\n        }\n        // Optional remote models support via env flag\n        const allowRemote = process.env.NEXT_PUBLIC_ALLOW_REMOTE_MODELS === 'true'\n        // Quick preflight: ensure local model files exist only when remote models are disabled\n        if (!allowRemote) {\n          try {\n            const probe = await fetch(`/models/${modelId}/config.json`, { method: 'HEAD' })\n            if (!probe.ok) {\n              throw new Error(\n                `Modelo local no encontrado en /models/${modelId}. Copia los archivos del modelo en public/models/${modelId}/`\n              )\n            }\n          } catch (e: any) {\n            throw new Error(e?.message || `No se pudo verificar el modelo local en /models/${modelId}`)\n          }\n        }\n\n        const { pipeline, env } = await import('@xenova/transformers')\n        // Only allow local models. Host model files under /public/models/<modelId>/\n        ;(env as any).allowRemoteModels = allowRemote\n        ;(env as any).localModelPath = '/models'\n\n        let pipe: TranslatorPipeline\n        try {\n          pipe = (await pipeline('translation', modelId)) as TranslatorPipeline\n        } catch (e: any) {\n          throw new Error(e?.message || 'No se pudo inicializar el pipeline de traducción con el modelo local')\n        }\n        return pipe\n      })()\n    }\n    return this.cache[modelId]\n  }\n\n  /** Translate long text by splitting into manageable chunks. */\n  private static async translateLargeText(text: string, translator: TranslatorPipeline): Promise<string> {\n    const chunks = this.chunkText(text, 500)\n    const outputs: string[] = []\n    for (const chunk of chunks) {\n      const result = await translator(chunk)\n      const translated = Array.isArray(result) ? result[0].translation_text : result.translation_text\n      outputs.push(translated)\n    }\n    return outputs.join(' ')\n  }\n\n  /** Simple sentence-based chunking with a max length safeguard. */\n  private static chunkText(text: string, maxLen: number): string[] {\n    const sentences = text.split(/(?<=[.!?])\\s+/)\n    const chunks: string[] = []\n    let current = ''\n    for (const s of sentences) {\n      if ((current + ' ' + s).trim().length <= maxLen) {\n        current = (current ? current + ' ' : '') + s\n      } else {\n        if (current) chunks.push(current)\n        current = s\n      }\n    }\n    if (current) chunks.push(current)\n    return chunks\n  }\n}"],"names":[],"mappings":"AAAA,8FAA8F;AAC9F,sEAAsE;;;;;AAEtE;;AAUA,wFAAwF;AACxF,MAAM,YAAyE;IAC7E,IAAI;QAAE,IAAI;QAAwB,IAAI;QAAwB,IAAI;QAAwB,IAAI;QAAwB,IAAI;IAAuB;IACjJ,IAAI;QAAE,IAAI;QAAwB,IAAI;QAAwB,IAAI;QAAwB,IAAI;QAAwB,IAAI;IAAuB;IACjJ,IAAI;QAAE,IAAI;QAAwB,IAAI;QAAwB,IAAI;QAAwB,IAAI;QAAwB,IAAI;IAAuB;IACjJ,IAAI;QAAE,IAAI;QAAwB,IAAI;QAAwB,IAAI;QAAwB,IAAI;QAAwB,IAAI;IAAuB;IACjJ,IAAI;QAAE,IAAI;QAAwB,IAAI;QAAwB,IAAI;QAAwB,IAAI;QAAwB,IAAI;IAAuB;IACjJ,IAAI;QAAE,IAAI;QAAwB,IAAI;QAAwB,IAAI;QAAwB,IAAI;QAAwB,IAAI;IAAuB;AACnJ;AAIO,MAAM;IACX,OAAe,QAAqD,CAAC,EAAC;IAEtE;;GAEC,GACD,aAAa,aAAa,OAA4B,EAAiB;QACrE,MAAM,EAAE,IAAI,EAAE,UAAU,EAAE,UAAU,EAAE,GAAG;QAEzC,wCAAmC;YACjC,MAAM,IAAI,MAAM;QAClB;QAEA,MAAM,UAAU,IAAI,CAAC,UAAU,CAAC,YAAY;QAC5C,MAAM,aAAa,MAAM,IAAI,CAAC,aAAa,CAAC;QAE5C,wBAAwB;QACxB,MAAM,QAAQ,MAAM,+IAAU,CAAC,kBAAkB,CAAC;QAElD,4DAA4D;QAC5D,MAAM,kBAAkB,EAAE;QAC1B,KAAK,MAAM,YAAY,MAAO;YAC5B,MAAM,aAAa,MAAM,IAAI,CAAC,kBAAkB,CAAC,UAAU,MAAM;YACjE,gBAAgB,IAAI,CAAC;QACvB;QAEA,wCAAwC;QACxC,MAAM,gBAAgB,MAAM,+IAAU,CAAC,sBAAsB,CAAC;QAC9D,OAAO;IACT;IAEA,0CAA0C,GAC1C,OAAe,WAAW,GAAiB,EAAE,GAAiB,EAAU;QACtE,IAAI,QAAQ,KAAK,MAAM,IAAI,MAAM;QACjC,MAAM,KAAK,SAAS,CAAC,IAAI,EAAE,CAAC,IAAI;QAChC,IAAI,CAAC,IAAI,MAAM,IAAI,MAAM,CAAC,qCAAqC,EAAE,IAAI,CAAC,EAAE,KAAK;QAC7E,OAAO;IACT;IAEA,kFAAkF,GAClF,aAAqB,cAAc,OAAe,EAA+B;QAC/E,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,QAAQ,EAAE;YACxB,IAAI,CAAC,KAAK,CAAC,QAAQ,GAAG,CAAC;gBACrB,qCAAqC;gBACrC,yEAAyE;gBACzE,kFAAkF;gBAClF,kDAAkD;gBAClD;oBACE,MAAM,IAAI;oBACV,qDAAqD;oBACrD,IAAI,CAAC,EAAE,OAAO,IAAI,OAAO,EAAE,OAAO,KAAK,UAAU;wBAC/C,EAAE,OAAO,GAAG;4BAAE,UAAU,CAAC;4BAAG,KAAK,CAAC;4BAAG,SAAS;wBAAK;oBACrD,OAAO;wBACL,MAAM,IAAI,EAAE,OAAO;wBACnB,IAAI,EAAE,QAAQ,IAAI,MAAM,EAAE,QAAQ,GAAG,CAAC;wBACtC,IAAI,EAAE,GAAG,IAAI,MAAM,EAAE,GAAG,GAAG,CAAC;wBAC5B,EAAE,OAAO,GAAG;oBACd;gBACF;gBACA,8CAA8C;gBAC9C,MAAM,cAAc,6CAAgD;gBACpE,uFAAuF;gBACvF;;gBAaA,MAAM,EAAE,QAAQ,EAAE,GAAG,EAAE,GAAG;gBAExB,IAAY,iBAAiB,GAAG;gBAChC,IAAY,cAAc,GAAG;gBAE/B,IAAI;gBACJ,IAAI;oBACF,OAAQ,MAAM,SAAS,eAAe;gBACxC,EAAE,OAAO,GAAQ;oBACf,MAAM,IAAI,MAAM,GAAG,WAAW;gBAChC;gBACA,OAAO;YACT,CAAC;QACH;QACA,OAAO,IAAI,CAAC,KAAK,CAAC,QAAQ;IAC5B;IAEA,6DAA6D,GAC7D,aAAqB,mBAAmB,IAAY,EAAE,UAA8B,EAAmB;QACrG,MAAM,SAAS,IAAI,CAAC,SAAS,CAAC,MAAM;QACpC,MAAM,UAAoB,EAAE;QAC5B,KAAK,MAAM,SAAS,OAAQ;YAC1B,MAAM,SAAS,MAAM,WAAW;YAChC,MAAM,aAAa,MAAM,OAAO,CAAC,UAAU,MAAM,CAAC,EAAE,CAAC,gBAAgB,GAAG,OAAO,gBAAgB;YAC/F,QAAQ,IAAI,CAAC;QACf;QACA,OAAO,QAAQ,IAAI,CAAC;IACtB;IAEA,gEAAgE,GAChE,OAAe,UAAU,IAAY,EAAE,MAAc,EAAY;QAC/D,MAAM,YAAY,KAAK,KAAK,CAAC;QAC7B,MAAM,SAAmB,EAAE;QAC3B,IAAI,UAAU;QACd,KAAK,MAAM,KAAK,UAAW;YACzB,IAAI,CAAC,UAAU,MAAM,CAAC,EAAE,IAAI,GAAG,MAAM,IAAI,QAAQ;gBAC/C,UAAU,CAAC,UAAU,UAAU,MAAM,EAAE,IAAI;YAC7C,OAAO;gBACL,IAAI,SAAS,OAAO,IAAI,CAAC;gBACzB,UAAU;YACZ;QACF;QACA,IAAI,SAAS,OAAO,IAAI,CAAC;QACzB,OAAO;IACT;AACF","debugId":null}}]
}